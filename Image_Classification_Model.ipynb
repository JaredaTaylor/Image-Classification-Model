{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf798513",
      "metadata": {
        "id": "cf798513"
      },
      "source": [
        "# Distracted Driver Detection\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VRLNrFDU3dKp",
      "metadata": {
        "id": "VRLNrFDU3dKp"
      },
      "source": [
        "1. Read and preprocesses data\n",
        "2. Create model\n",
        "3. Train model\n",
        "4. Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b7e6a263",
      "metadata": {
        "id": "b7e6a263"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "#from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee278a0",
      "metadata": {},
      "source": [
        "# Preprocessing of Driver Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3a19bd78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a19bd78",
        "outputId": "a0089e95-400c-4620-a560-c758599afcd5"
      },
      "outputs": [],
      "source": [
        "#preprocessing class\n",
        "class PreProcessing:\n",
        "  \"\"\"\n",
        "  Goes through all images, returns preprocessed tensor.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, base_path):\n",
        "      self.base_path = base_path\n",
        "      self.kernel = np.array([[-1, -1, -1],\n",
        "                   [-1, 8,-1],\n",
        "                   [-1, -1, -1]])\n",
        "      print(self.base_path)\n",
        "\n",
        "  def get_colour_type(self, img_path):\n",
        "    image = cv2.imread(img_path)\n",
        "    if len(image.shape) == 3: return 3\n",
        "    else: return 1\n",
        "\n",
        "  def preprocess_image(self, img_path, height, width):\n",
        "    \"\"\"\n",
        "    Function takes the path to the image and applys the preprocessing.\n",
        "    \"\"\"\n",
        "\n",
        "    color_type = self.get_colour_type(img_path)\n",
        "\n",
        "    if color_type == 1:\n",
        "        img = cv2.imread(img_path, 0)\n",
        "        img_gray = cv2.threshold(img,0,255,cv2.THRESH_TRUNC+cv2.THRESH_OTSU) \n",
        "        image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=self.kernel)\n",
        "\n",
        "    elif color_type == 3:\n",
        "        img = cv2.imread(img_path)\n",
        "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img_gray = cv2.threshold(img_gray,0,255,cv2.THRESH_TRUNC+cv2.THRESH_OTSU)\n",
        "        image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=self.kernel)\n",
        "        image_sharp = cv2.cvtColor(image_sharp, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "\n",
        "    combined = cv2.add(image_sharp, img_gray[1])\n",
        "    dst = cv2.resize(combined, (width, height))\n",
        "    dst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
        "    \n",
        "    return dst\n",
        "\n",
        "  def get_driver_data(self):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of image name as the key and driver and class as value.\n",
        "    \"\"\"\n",
        "    driver_data = {}\n",
        "    path = os.path.join(self.base_path,'driver_imgs_list.csv')\n",
        "\n",
        "    print('Read drivers data')\n",
        "\n",
        "    with open(path, 'r') as file:\n",
        "      lines = file.readlines()\n",
        "      lines = lines[1:]\n",
        "    file.close()\n",
        "\n",
        "    for line in lines:\n",
        "      arr = line.strip().split(',')\n",
        "      driver_data[arr[2]] = (arr[0], arr[1])\n",
        "    \n",
        "    return driver_data\n",
        "\n",
        "  def load_train_data(self, height, width):\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    driver_ids = []\n",
        "\n",
        "    driver_data = self.get_driver_data()\n",
        "\n",
        "    print('Read train images')\n",
        "    for class_number in range(10):\n",
        "        print(f'Load folder c{class_number}')\n",
        "        class_number_str = 'c' + str(class_number)\n",
        "        path = os.path.join(self.base_path, 'imgs/train', class_number_str, '*.jpg')\n",
        "        file_paths = glob.glob(path)  # Gets all file names matching given path.\n",
        "        for file_path in file_paths:\n",
        "            file_name = os.path.basename(file_path)\n",
        "            image = self.preprocess_image(file_path, height, width)\n",
        "            x_train.append(image)\n",
        "            y_train.append(class_number)\n",
        "            driver_id = driver_data[file_name][0]\n",
        "            driver_ids.append(driver_id)\n",
        "\n",
        "    return x_train, y_train, driver_ids\n",
        "\n",
        "  # Not used since data has no classification\n",
        "  def load_test_data(self, height, width):\n",
        "    x_test = []\n",
        "    x_test_ids = []\n",
        "    \n",
        "    print('Read test images')\n",
        "\n",
        "    path = os.path.join(self.base_path, 'imgs/test/*.jpg')\n",
        "    file_paths = glob.glob(path)\n",
        "    number_of_files = len(file_paths)\n",
        "\n",
        "    for count, file_path in enumerate(file_paths):\n",
        "        file_name = os.path.basename(file_path)\n",
        "        image = self.preprocess_image(file_path, height, width)\n",
        "        x_test.append(image)\n",
        "        x_test_ids.append(file_name)\n",
        "        if count % 1000 == 0:\n",
        "            print(f\"Read {count} images from {number_of_files}\")\n",
        "\n",
        "    return x_test, x_test_ids\n",
        "\n",
        "\n",
        "  def split_train_data(self, x_train, y_train, driver_ids):\n",
        "    '''\n",
        "    split the data into train and test sets\n",
        "    divide data based on driver_ids, this gives the divison of ~73% in train and ~27% in test\n",
        "    '''\n",
        "    idList = []\n",
        "    newTrain_x = []\n",
        "    newTrain_y = []\n",
        "    newTest_x = []\n",
        "    newTest_y = []\n",
        "    for driver in driver_ids:\n",
        "        if driver not in idList:\n",
        "            idList.append(driver)\n",
        "    trainData = idList[:20]\n",
        "    testData = idList[20:]\n",
        "    #iterate trough x_train, compare driver_ids\n",
        "    for ind in range(len(x_train)):\n",
        "        if driver_ids[ind] in trainData:\n",
        "            newTrain_x.append(x_train[ind])\n",
        "            newTrain_y.append(y_train[ind])\n",
        "        if driver_ids[ind] in testData:\n",
        "            newTest_x.append(x_train[ind])\n",
        "            newTest_y.append(y_train[ind])\n",
        "    return newTrain_x, newTrain_y, newTest_x, newTest_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7cdbfd54",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "Read drivers data\n",
            "Read train images\n",
            "Load folder c0\n",
            "Load folder c1\n",
            "Load folder c2\n",
            "Load folder c3\n",
            "Load folder c4\n",
            "Load folder c5\n",
            "Load folder c6\n",
            "Load folder c7\n",
            "Load folder c8\n",
            "Load folder c9\n"
          ]
        }
      ],
      "source": [
        "#get processed data\n",
        "PATH = 'data'\n",
        "p = PreProcessing(PATH)\n",
        "x_train, y_train, driver_ids = p.load_train_data(224, 224)\n",
        "#newTrain_x, newTrain_y, newTest_x, newTest_y = p.split_train_data(x_train, y_train, driver_ids)\n",
        "#print(len(x_train))\n",
        "#print(len(newTrain_x) + newTest_x)\n",
        "#x_test, x_test_id = p.load_test_data(224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "34fd2e47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "34fd2e47",
        "outputId": "060ac4d2-2fe3-4498-f839-bbd121ddde16",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function destroyAllWindows>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data visualization\n",
        "temp = x_train[np.random.randint(0, len(x_train))]\n",
        "temp = x_train[np.random.randint(0, len(x_train))]\n",
        "cv2.imshow('image', temp)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "06c93a78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06c93a78",
        "outputId": "bec39077-e72b-4702-b45c-d87a41f6516f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16458\n",
            "5966\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\nfor img in range(len(newTrain_x)):\\n    c = newTrain_y[img]\\n    filename = 'trainImage' + str(img) + '.png'\\n    directory = r'C:/Users/setcl/Documents/Work/School/5th Year/Fall/Neural & Genetic/Research Project/ppdata/train/' + str(c)\\n    print(directory)\\n    os.chdir(directory)\\n    image = newTrain_x[img]\\n    cv2.imwrite(filename, image)\\n\\nfor img in range(len(newTest_x)):\\n    c = newTest_y[img]\\n    filename = 'testImage' + str(img) + '.png'\\n    directory = r'C:/Users/setcl/Documents/Work/School/5th Year/Fall/Neural & Genetic/Research Project/ppdata/test/' + str(c)\\n    os.chdir(directory)\\n    image = newTest_x[img]\\n    cv2.imwrite(filename, image)\\n\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split train data\n",
        "newTrain_x, newTrain_y, newTest_x, newTest_y = p.split_train_data(x_train, y_train, driver_ids)\n",
        "print(len(newTrain_x))\n",
        "print(len(newTest_x))\n",
        "\n",
        "# save new train data\n",
        "'''\n",
        "for img in range(len(newTrain_x)):\n",
        "    c = newTrain_y[img]\n",
        "    filename = 'trainImage' + str(img) + '.png'\n",
        "    directory = r'train_path' + str(c)\n",
        "    print(directory)\n",
        "    os.chdir(directory)\n",
        "    image = newTrain_x[img]\n",
        "    cv2.imwrite(filename, image)\n",
        "\n",
        "for img in range(len(newTest_x)):\n",
        "    c = newTest_y[img]\n",
        "    filename = 'testImage' + str(img) + '.png'\n",
        "    directory = r'test_path' + str(c)\n",
        "    os.chdir(directory)\n",
        "    image = newTest_x[img]\n",
        "    cv2.imwrite(filename, image)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3c528d44",
      "metadata": {
        "id": "3c528d44"
      },
      "outputs": [],
      "source": [
        "def evaluator(y_test, y_pred):\n",
        "    ####################################################################################################\n",
        "    # enter code here to implement the evaluation matrices including confusion matrix, accuracy, precision and recall\n",
        "    \n",
        "    #initialize confusion matrix\n",
        "    pass\n",
        "\n",
        "    ####################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4a6b06",
      "metadata": {
        "id": "4e4a6b06"
      },
      "source": [
        "## Inception-V3 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "883bc04c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 16458 images belonging to 10 classes.\n",
            "Found 5966 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# define data generators\n",
        "trainDir = 'train_path'\n",
        "testDir = 'test_path'\n",
        "\n",
        "trainDataGen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255) #, rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, zoom_range = 0.2, shear_range = 0.2, horizontal_flip = True, fill_mode = 'nearest')\n",
        "testDataGen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "trainGenerator = trainDataGen.flow_from_directory(trainDir, batch_size = 100, class_mode = 'categorical', target_size = (224, 224))\n",
        "testGenerator = testDataGen.flow_from_directory(testDir, batch_size = 100, class_mode = 'categorical', target_size = (224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "53d44741",
      "metadata": {},
      "outputs": [],
      "source": [
        "# callback to stop training at certain threshold\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "    \n",
        "    # change cause won't ever happen\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "        if (logs.get('acc') > 0.99 and logs.get('val_acc') > 0.99):\n",
        "            print('\\nCancelling training as model reached 99 accuracy and 99 validation acc.')\n",
        "            self.model.stop_training == True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "9785b703",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot results\n",
        "def plotResult(history):\n",
        "    acc = history.history['accuracy']\n",
        "    valAcc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    valLoss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'r', label = 'Training Accuracy')\n",
        "    plt.plot(epochs, valAcc, 'b', label = 'Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend(loc = 0)\n",
        "    plt.figure()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "29d82a53",
      "metadata": {
        "id": "29d82a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_133 (Conv2D)         (None, 223, 223, 32)      416       \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 111, 111, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_134 (Conv2D)         (None, 110, 110, 32)      4128      \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 55, 55, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_135 (Conv2D)         (None, 54, 54, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 27, 27, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1024)              47776768  \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47,799,818\n",
            "Trainable params: 47,799,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\setcl\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# CNN model\n",
        "width, height = 224, 224\n",
        "\n",
        "inputShape = (width, height, 3)\n",
        "\n",
        "inputLayer = keras.layers.Input(shape = inputShape)\n",
        "outputLayer = keras.layers.Dense(10, activation = 'softmax')\n",
        "\n",
        "x = keras.layers.Conv2D(32, (2, 2), activation = 'relu')(inputLayer)\n",
        "x = keras.layers.MaxPooling2D(pool_size = (2, 2))(x)\n",
        "\n",
        "x = keras.layers.Conv2D(32, (2, 2), activation = 'relu')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size = (2, 2))(x)\n",
        "\n",
        "x = keras.layers.Conv2D(64, (2, 2), activation = 'relu')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size = (2, 2))(x)\n",
        "\n",
        "x = keras.layers.Flatten()(x)\n",
        "\n",
        "x = keras.layers.Dense(1024, activation = 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "outputLayer = keras.layers.Dense(10, activation = 'softmax')(x)\n",
        "\n",
        "#if input_tensor\n",
        "\n",
        "cnnModel = keras.Model(inputs = inputLayer, outputs = outputLayer)\n",
        "cnnModel.compile(optimizer = keras.optimizers.RMSprop(lr = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "cnnModel.summary()\n",
        "#keras.utils.plot_model(cnnModel, to_file='cnn_model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "a2bc6d80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "165/165 [==============================] - 381s 2s/step - loss: 1.7722 - accuracy: 0.4264 - val_loss: 1.8052 - val_accuracy: 0.3932\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 375s 2s/step - loss: 0.5801 - accuracy: 0.8605 - val_loss: 1.8467 - val_accuracy: 0.4583\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 375s 2s/step - loss: 0.1753 - accuracy: 0.9611 - val_loss: 1.9864 - val_accuracy: 0.4844\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 375s 2s/step - loss: 0.0663 - accuracy: 0.9843 - val_loss: 2.5642 - val_accuracy: 0.4574\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 370s 2s/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 2.6455 - val_accuracy: 0.4824\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 366s 2s/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 2.5608 - val_accuracy: 0.4618\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 369s 2s/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 3.0793 - val_accuracy: 0.4150\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 367s 2s/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 3.1544 - val_accuracy: 0.4732\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 361s 2s/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 4.7638 - val_accuracy: 0.4454\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 362s 2s/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 3.7125 - val_accuracy: 0.4574\n"
          ]
        }
      ],
      "source": [
        "# train/fit model\n",
        "callbacks = myCallback()\n",
        "history = cnnModel.fit(x = trainGenerator, validation_data = testGenerator, validation_freq = 1, epochs = 10, verbose = 1) #steps_per_epoch = 100, validation_steps = 100, callbacks = [callbacks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "9a221df3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot training and results\n",
        "print(history.history.keys())\n",
        "plotResult(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3e567f44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e567f44",
        "outputId": "2bab9466-578c-4ced-cac8-0294abe24044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 36s 0us/step\n",
            "96124928/96112376 [==============================] - 36s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#build and train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b29fccb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3830d2ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "3830d2ef",
        "outputId": "431706ac-81b4-4aad-883b-88f6c21a329b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n        plt.plot(model1.history['train_acc'], label='train_acc')\\n        plt.plot(model1.history['test_acc'], label='test_acc')\\n        plt.legend()\\n        plt.show()\\n\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#plot results\n",
        "'''\n",
        "        plt.plot(model1.history['train_acc'], label='train_acc')\n",
        "        plt.plot(model1.history['test_acc'], label='test_acc')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "409344f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "409344f7",
        "outputId": "c211fdb1-31b8-4fa3-8efe-269e36bcce94",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#predict\n",
        "#y_pred = model1.predict(x_test)\n",
        "#evaluator(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "A1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
